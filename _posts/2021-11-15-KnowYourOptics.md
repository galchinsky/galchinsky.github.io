---
layout : post
title : "Знай свои данные: дебрлюр"
---

Знай свои данные: деблюр

== Основы оптики ==

Здесь описано, почему сложно сделать идеальное изображение, и какие проблемы есть с тем, что дают нам объективы из реального мира. Этим проблемам даны названия.

Обычно свет распространяется от видимого предмета сразу во все стороны. Поэтому, если взять белый лист бумаги, на нем не будет ничего отображаться - лучи падают на этот лист со всех сторон, перемешиваясь. Фильмы про хакеров врут: такое, как на картинке, невозможно.

Чтобы увидеть на белом листе предметы, нужна штука, которая вычленит лучи от какой-то конкретной точки из этой электромагнитной каши. Простейший способ - небольшая дырка. Из всех лучей, падающих на нас, отсекаем небольшую область. Ставим на пути лучей плоскость. Получаем изображение. Чем меньше дырка, чем четче изображение.

Но возникают трудности - световой энергии через дырку проходит мало. Чем меньше дырка, тем тусклее. 

В компьютерной графике, где об энергии можно не заботиться, такой способ построения изображений стал основным. Это удобно, потому что геометрическая задача несложная: провести прямую через 2 точки и найти пересечение с плоскостью. Для пущей простоты в компьютерах меняют местами плоскость и дырку. Физически это уже неосуществимо, зато изображение не переворачивается.

В реальном же мире используют линзы. Линза собирает лучи с большей области пространства, и направляет их примерно в одну точку. Получается намного ярче. Но возникают новые проблемы. С дыркой у нас все было настолько четко, насколько эта дырка маленькая. С линзой все начинает зависеть от того, где расположен лист, но даже если он расположен в наилучшем месте, все равно где-то будет более размыто, где-то менее. У дырки прямые линии остаются прямыми. Линза будет их гнуть.

Проблема нулевая - когда у нас простая дырка, перемещение плоскости меняет в основном размер изображения. Линзе же не все равно, на каком расстоянии предмет. Если он бесконечно далеко, как звезда, а лучи падают почти параллельно - плоскость должна быть в одном месте. Если предмет близко - то в другом. Необходим способ *фокусироваться* - менять на лету расстояние между линзой и плоскостью, подстраиваясь под расстояние до предмета. Также появляется понятия глубины резкости - некоторые линзы изображают четко довольно большие области, с некоторыми в фокус еще попасть нужно. Так как объективы в наше время делать более-менее умеют, есть мысль, что нулевая проблема - основная.

Проблема первая - технологически проще всего делать плоские и сферические поверхности. Берешь шар, трешь об него стекло как угодно- стекло примет форму вогнутого шара. То же самое с выпуклым шаром и плоскостью. С другой поверхностью так не получится, потому что в разных местах будет разная кривизна. Но геометрическая фигура, которая сводит лучи идеально в точку - параболоид. Для тех, кто забыл, параболоид это z=x^2+y^2, а сфера - z=sqrt(z^2+y^2). Параболоид сделать тяжелее. Компромисс - найти такую сферу, чтобы она максимально повторяла параболоид. Идеально такую линзу сфокусировать нельзя, в минимальном случае будет небольшое пятно. Это пятно называется сферической аберрацией. Если в оптической системе используется что-то, кроме сфер, это называется асферической оптикой. Сейчас этим никого не удивишь, но по-прежнему точную сферу сделать намного проще, поэтому количество таких поверхностей стараются минимизировать.

Проблема вторая - линза преломляет красные, зеленые и синие лучи слегка по-разному. В итоге, там, где зеленые лучи сведены минимально, красные и синие будут чуть шире. Если передвинуть плоскость, чтобы красные стали четкими - зеленые и синие разъедутся. Это называется хроматической аберрацией. Максимальную четкость зеленого считают основной, потому что так считает глаз.

Проблема третья - если предмет находится не на оси, лучи перекашивает еще больше, а размытое пятно, похожее на гауссоиду, становится ассиметричным, и похожим то ли на запятую, то ли на комету. Это называется комой.

Проблема четвертая - все может быть четко, но прямые линии не быть прямыми. Это называется дисторсией.

Итого: расфокус, сферическая аберрация, кома, хроматическая аберрация и дисторсия.

Есть еще куча проблем, вызваными теми или иными отклонениями изображения от идеального, астигматизм, например, но они не так важны, если вы не собираетесь делать свой объектив.

Решение всех этих проблем с точки зрения технологии - использовать не одну линзу, а много, и не из одного типа стекла, а из разных. Там, где нужна компактность, использовать асферические поверхности. Но идеала все равно нет. Хотя бы потому, что автофокус все равно может налажать. Поэтому в пост-процессинге бывает нужен деблюр.

Мутный мрак

Задача деблюра - из мутного изображения сделать четкое. Соответственно нужно научиться из четкого изображения делать мутное, и обучить нейронку делать наоборот.

Где взять четкое изображение? Ну, например, скачать картинку 4096х4096, убедиться, что она в фокусе, и ресайзнуть до 512х512 идеальным алгоритмом без алиасинга. Даже если объектив имел какие-то недостатки, при таком ресайзе они пропадут. NB. Аугментации типа поворта должна делаться до ресайза.

Рецептов, как убедиться, что картинка четкая, в интернете много. https://stackoverflow.com/questions/7765810/is-there-a-way-to-detect-if-an-image-is-blurry Они сводятся к тому, что в четком изображении много высоких частот, а значит можно сделать фильтр высоких частот, который что-то скажет о четкости.

Сделать четкое изображение мутным сложнее, чем будет посвящен остаток поста.

== Трассировка лучей через линзу ==

Задача стоит такая: допустим, у нас есть какое-то идеальное изображение, которое мы распечатали и поместили на расстоянии 30 м от линзы. Какое изображение эта линза создаст? Решение в лоб - пройтись циклом по каждой точке распечатанного изображения. Послать много лучей в сторону линзы, они в ней преломятся и упадут в нашу плоскость. Там мы разлинуем все на пиксели, посчитаем их число лучше, попавших в каждый пиксель, все, посчитали. В природе оно примерно так и работает. Проблема в том, что это очень долго.

Но нас спасет следующее предположение: два соседних пикселя должны размываться примерно одинаково. Соответственно, не нужно трассировать каждый пиксель, если мы оттрасировали один, то сосед будет размываться примерно так же. И сосед соседа. Поэтому, мы можем посчитать, как размываются пиксели, допустим, по сетке 64х64, а вид размытия промежуточных пикселей плавно интерполировать.

Так мы приходим к PSF.

== PSF ==

PSF - "функция рассеяния точки". Берем очень маленькую, но очень яркую лампочку. Светим на объектив. В идеальном случае точка останется точкой на изображении. В реальности она будет размыта. Вот получившееся изображение маленькой размытой лампочки и называется PSF.

1. Гаусс

Если мы устанавливаем лампочку в разные места, а PSF все время постоянная (то есть лампочка сдвигается, но картина размытости остается той же), можно использовать свертку. Встречается ли такое в реальности? Ну, при сильном расфокусе, наверное, если у объектива небольшое поле зрения. 

При таком расфокусе изображение маленькой и яркой лампочки превращается во что-то типа гауссоиды. Вот мы и придумали guassian blur из фотошопа. Идеальный алгоритм для старых медленных компьютеров, основую суть выхватывает, будучи очень простым.

filtered_image = scipy.ndimage.gaussian_filter(input, sigma)

Внутри там что-то типа

kernel = gkern(kernel_size, sigma)
filtered_image = np.convolve2d(image, kernel)

Единственный параметр тут - sigma, управляет силой размытия. Можно подогнать sigma под величину PSF вручную. Второй параметр - kernel_size, больше касается скорости обработки. Если его поставить слишком маленьким, пятно станет таким толстым, что вытечет из экрана. 

Так как 99,7% энергии попадает в круг +-6 sigma, примерно такого размера kernel_size и нужно делать.

Хроматическая аберрация имитируется разными сигмами для разных каналов:

filtered_image = np.zeros_like(input)
filtered_image[:, :, 0] = scipy.ndimage.gaussian_filter(input[:, :, 0], sigma_r)
filtered_image[:, :, 1] = scipy.ndimage.gaussian_filter(input[:, :, 1], sigma_g)
filtered_image[:, :, 2] = scipy.ndimage.gaussian_filter(input[:, :, 2], sigma_b)

Вместо функции Гаусса можно использовать другие, похожие функции.

2. Кома

Если мы обучаем на мелких кропах, PSF можно считать постоянной в пределах кропа. Но использовать только гауссово размытие неправильно, потому что оно соответствует идеально симметричной PSF. Ближе к краю кадра эта симметрия, как правило, нарушается. Как сгенерировать PSF  с перекосом? Можно делать это с помощью накладывания множества гауссоид в цикле. Алгоритму требуется начальная, конечная точка и то, как меняется ширина пятна. Диапазоны для рандомизатора можно установить, внимательно изучив PSF реальных объективов.

3. Моушен блюр

Источником размытия является не только оптика, но и тот факт, что мы считаем попавшие в нас лучи конечное время. Если предмет за это время сдвинется, изображение будет смазанным.

4. Сколько PSF нужно

Объективы осесимметричны. То есть если в точке (5; 0) мы имеем PSF, то в точке (0; 5) будет такая же картина, но повернутая на 90 градусов. Это позволяет ввести функцию PSF(r), посчитав PSF только вдоль одной линии от центра к краю. Для остальных мест нужно найти r=sqrt(x^2+y^2) и просто повернуть изображение на atan2(y, x). Когда разговор заходит о поворотах и ресайзах, нужно убедиться, что у исходного изображения достаточно разрешения. Поэтому посчитать PSF сеткой по x и y тоже подход неплохой. Тогда в узловых точках мы вычисляем PSF(x, y), между ними - интерполируем между 4 ближайшими PSF. Все зависит от того, насколько дорого считать PSF. Когда я пришел на свою первую работу, как это автоматизируется я не знал, и мне давали какие-то таблички оптики, которые вручную считали в Zemax. Мне это не понравилось, и я форкнул GNU Optical, чтобы считать это автоматически.

5. Переменная свертка

Простая свертка двух массивов это 4 вложенных цикла с примерно таким содержимым:

for x изображения
 for y изображения
  for x кернела
   for y кернела
       результат[x первого, y_первого] += изображение[x первого+x второго, y_первого+y_второго] * кернел[x второго, y второго]

Если у нас кернел разный для разных пикселей:

for x изображения    
 for y изображения    
  кернел = PSF(x, y)
  for x кернела        
   for y кернела        
       результат[x первого, y_первого] += изображение[x первого+x второго, y_первого+y_второго] * кернел[x второго, y второго]

мы получаем переменную свертку. Так как PSF у нас вычислен с каким-то шагом, для промежуточных пикселей PSF(x, y) можно интерполировать по 4-м ближайшим известным PSF. Если писать код как композицию функций, он даже не будет ужасным.

5. LocallyConnectedLayer

Слой для переменной свертки называется так. В теории, можно загрузить в него нужные веса, и размывать на GPU. Он занимает много памяти, потому что хранит кернел для каждого пикселя. Но зато PSF для каждого пикселя вычисляется всего один раз.

6. Нечто среднее между сверткой с одним PSF на все изображение и переменной сверткой

Разбиваем изображение на перекрывающиеся квадраты. Размываем в них по-разному (в зависимости от PSF в данной области кадра). Собираем изображение назад. Чтобы избежать краевых эффектов, блендим изображения плавно между собой, используя что-то типа hann window. В общем, ovelap-add.

7. Расстояние

Все вышеперечисленное справедливо для плоских предметов, установленных параллельно изображению. В реальности PSF еще зависит от расстояния. Псевдокод в итоге превратится в

for x изображения    
 for y изображения    
  кернел = f(x,y, глубина(x, y))
  for x кернела
   for y кернела
       результат[x первого, y_первого] += изображение[x первого+x второго, y_первого+y_второго] * кернел[x второго, y второго]

Карту глубин можно попробовать получить соответствующей нейросетью.

8. Дальнейшие усложения модели

Если превратить массив в функцию, позволяя адресоваться не только к конкретным пикселям, но и между ними, за счет интерполяции, можно встроить motion blur:

for t, dx, dy
 for x изображения
  for y изображения
   кернел = f(x,y, глубина(x, y))
   for x кернела
    for y кернела
        результат[x первого, y_первого] += изображение(x первого+x второго+dx, y_первого+y_второго+dy) * кернел[x второго, y второго]

Затем, можно накладывать байероский фильтр, шум, имитирующий фотоприемник (тоже от простейшего гауссова шума, до сложных моделей). Смысла в такой подробности я не вижу, но можно и так.

== Выводы ==

Оптимальным считаю генерацию кома-подобных аберраций на лету, размытие с помощью свертки, и обучение на малых кропах. PSF, полученные в результате трассировки лучей, следует использовать только для установки правильных значений рандомизатора, чтобы результирующие сгенерированные PSF были похожи на те, что имеет реальный объектив.

Имплементируется это в несколько строчек, а польза более сложных моделей сомнительна. Если малые кропы по какой-то причине обучаются плохо, overlap-add должен помочь.
