---
layout: post
title:  Про достижение воспроизводимости в ML
---

Есть две крайности. Первая - не думать о воспроизводимости вообще, надеясь на память, какие-то записки и содержимое репозитория.
Вторая - трекинг софтом типа DVC, который сам записывает какие-то действия, считает хэши, заливает в облако, и все такое.

Мне обе этих крайности не нравятся. Если забить на нее, мозг вместо занятия полезными делами должен помнить какую-то чушь, а ошибки съедают иногда часы. При чем начинается это довольно быстро. Вторая превращает простую в общем-то задачу в кровавый энтерпрайз с километровыми конфигурациями, где ты должен описать стадии, с md5 хэшами, справками и печатями. Удобный же подход где-то посередине - ты пишешь код, используя простые правила, а при желании восстанавливаешь весь рабочий процесс от начала и до конца.

Я попробовал собрать правила, которые применяю сам. Они позволяют почти не разводить бюрократию а-ля DVC, но при этом пайплайн при желании вспоминается за пять минут, и не нужно думать о том, как запустить модель, задеплоеную полгода назад и забытую.

Есть три сущности в виде файлов: скрипт, конфиг и данные.

* Скрипт берет на вход данные и конфиг, и выдает другие данные, обрабатывая их согласно тому, что написано в конфиге.
* Конфиг декларативно описывает то, что нужно сделать. Прочитать такую-то папку, создать нейронку с такой-то архитектурой. 
* Данные лежат и ничего не делают.

Сами правила:

* Главное требование к скриптам - обратная совместимость. Любой скрипт должен уметь взять прошлогодний конфиг, отработать и получить тот же результат. Никаких model_baseline.py и model_my_new_super_arch.py быть не должно. Есть model.py и model.json, в model.json указываем "arch" : "baseline". В model.py прописываем условие, вызывающее построение одной или другой архитектуры.

Основной друг здесь - дефолтные значения. Допустим, мы решили протестить модель, у которой в слое не 5 фильтров, а 10. Конфиг загружен в переменную params, которая доступна везде в коде. В коде пишем Conv(params.get("kolvo_kanalov", 5), ...). Копируем конфиг, добавляем в него строчку "kolvo_kanalov" : 10. Старые конфиги работают, потому params.get не найдет новый ключ и вернет 5, новая модель тоже работает с числом фильтров 10.

* Результат работы скрипта складывается в папочку. В скрипте делом создаем эту папку, сразу же после парсинга аргументов.

* В эту же папочку копируется конфиг, который был указан при вызове скрипта. Самая важная мелочь. Проснулись 1 января, видим папку, и не помним, откуда она взялась, а внутри там .json файлик, в котором понятно, что перед нами. Копируем файл используя open(..., 'x'). 'x' - создает файл, только если он уже не существует. Поэтому, если конфиг там уже лежит, скрипт упадет и ничего не затрет.

* Как защита от дурака, и скрипты, и конфиги сохраняются в репозиторий. Именно как защита от дурака, потому что если все сделано правильно, то откатываться к каким-то коммитам для запуска чего-то не придется. Есть только последняя версия кода. Данные в репозитории не лежат, им там делать нечего, поэтому репозиторий маленький и легкий

* Конфиги иммутабельны: если конфиг изменен, это должен быть новый конфиг с новым именем. Правило чисто на словах.

* Типичная ошибка - когда результат выполнения скрипта зависит от параметров командной строки. Например, число фильтров в конфиге есть, а лернингрейта нет. Не должно так быть, все должно определяться только конфигом. Для того, чтобы было удобно, используется трюк, при котором через командную строку можно модифицировать конфиг на лету. Выглядеть это может как `python script.py -c config.json --conf '{"lr" : 1e-3}'`. В скрипте после чтения config.json нужно примержить к нему строку, переданную в args.conf. Затем измененный конфиг сохранить в папку с результатами.

* Самая соблазнительная ошибка - "ну тут идейку проверить, быстренько поменяю код, потом верну". Добавить лишнее ветвление в код с дефолтным значением занимает меньше минуты: вместо 10 нужно написать params.get("moynoviyporametr", 10), далее при запуске нужно добавить --conf '{\"moynoviyparametr\": 10}'. Сильно дольше? Нет, даже если печатать одним пальцем. Если быстренькая идейка оказалась так себе, потом ее можно точно так же удалить. Но нервов сэкономит кучу.

* Минус подхода - иногда код полон лишних ветвлений для запуска древних и не нужных моделей, и захламляет все. Это можно и нужно рефакторить.

* Еще одна защита от дурака - все результирующие файлы не должны переписываться. Выше было сказано про конфиг в папочке с результатами, который не должен переписываться, если уже существует. Но вообще нужно всегда открывать файлы как open(..., 'x') либо 'r'.

* Конфиг должен быть максимально плоскими парами ключ-значение и без оверинжиниринга. То есть {"loss_l1_weight" : 1, "loss_l2_weight" : 0} вместо {losses : [{"l1":0}, {"l2:0}]}. Причина - так проще смотреть диффы.

Базовые скрипты:

* make_dataset.py: берет данные и пакует их в более машиноудобный формат.
* augment.py: берет данные из машиноудобного формата и генерирует аугментированные данные
* train.py: берет аугментированные данные и генерирует модель, а также график лоссов

Соответственно, нужно три кофига: data.json, augmentation.json и model.json.

* data.json - содержит пути к файлам как входные данные. Здесь удобно использовать модуль glob и маски. Например "dataset/images/**/*.jpg" заставит перебрать все жпеги в папке рекурсивно. Помимо этого, там же содержатся имена выходных файлов, например, data.bin и metadata.json
* augmentation.json - содержит {"source" : "data.json"} как входные данные, этот конфиг читается, из него берется data.bin и metadata.json и что-то делается, а на выходе - генератор потока аугментированных данных
* model.json - содержит {"source" : "augmentation.json"} как входные данные, оно передается в augmentation.py, на выходе уже тренированная модель

Каждый последующий конфиг содержит имя предыдущего как один из параметров, таким образом формируется направленный граф/пайплайн.

Помимо этого, есть еще predict.py, evaluate.py, export.py и тому подобные вещи, которые, читая model.json, генерируют что-то более приземленное.

В долгоживущем проекте вся движуха начинается крутиться вокруг правки конфигов, потому что весь код уже написан. Соответственно, здесь есть простор для скриптов, каждый из которых кажется не особо важным, но экономит две минуты времени в консоли.

* plot_losses.py - принимает набор model-конфигов и выдает лоссы
* jsondiff.py - принимает набор конфигов и выдает только отличающиеся параметры. У меня это csv-файл, который и в консоли читаем, и с помощью ">results.csv" можно в экселе открыть, если сравнивать нужно много файлов
* clone.py - копирует конфиг, меняя параметры, и добавляя к его имени букву a. Если существует - букву b

Для совсем лютых случаев я использовал дендрограммы, позаимствованные у биологов. А что, конфиг - практически генетический код. Можно их мутировать, женить, и всячески по-другому менять.

Уровень паранойи регулируется согласно требованиям проекта. Например, если датасет меняется часто, можно считать чексумму директории и сохранять список файлов.

Что с распределенностью? Конфиги можно хранить в монге. Тогда скрипту-воркеру остается подгрузить данные из распределенной ФС, посчитать, что нужно, и сохранить данные в распределенную ФС, апдейтнув монгу, что конфиг посчитан и лежит там-то. Я завел правило, что если у меня от бейслайна отпочковывается конфиг вручную, к его имени добавляется буква. Если для гридсерча создана сотня конфигов и они перебираются в облаке - цифра. Периодически удачные модели получают имена собственные.
